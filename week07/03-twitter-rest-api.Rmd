---
title: "Scraping data from Twitter's REST API"
date: November 19, 2019
output: github_document
---

```{r set-options, echo=FALSE, cache=FALSE}
options(width = 90)
```

We'll now turn to a different type of Twitter data -- static data, either recent tweets or user-level information. This type of data can be retrieved with Twitter's REST API. We will use the `tweetscores` package here -- this is a package that Pablo Barbera created to facilitate the collection and analysis of Twitter data.

### Searching recent Tweets

It is possible to download recent Tweets, but only up those less than 7 days old, and in some cases not all of them.

The following code will authorize your token and get the last 1,000 Tweets mentioning "brexit" and "election", using the **rtweets** package.

```{r}
library("rtweet")

load("my_oauth.rda")
twitter_token <- create_token(app = "Ken's R access", 
                              consumer_key = my_oauth$consumer_key,
                              consumer_secret = my_oauth$consumer_secret,
                              access_token = my_oauth$access_token,
                              access_secret = my_oauth$access_token_secret)

tweets <- search_tweets("brexit AND election", n = 1000)
head(tweets)
```

What are the most popular hashtags?
```{r}
library("stringr")
ht <- str_extract_all(tweets$text, "#[A-Za-z0-9_]+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
```

You can check the documentation about the options for string search [here](https://dev.twitter.com/rest/public/search).

### Extracting users' profile information

This is how you would extract information from user profiles:

```{r}
users <- lookup_users(c("realDonaldTrump", "POTUS", "VP", "FLOTUS"))
users
```

Which of these has the most followers?
```{r}
users[which.max(users$followers_count), ]
users$screen_name[which.max(users$followers_count)]
users[, c("screen_name", "followers_count")]
```

### Downloading recent tweets from a specific user

Download recent tweets from a specific account:
```{r}
tweets <- get_timeline("realDonaldTrump", n = 1000)
```

What are the most common hashtags?
```{r}
ht <- str_extract_all(tweets$text, "#[A-Za-z0-9_]+")
ht <- unlist(ht)
head(sort(table(ht), decreasing = TRUE))
```


### Other types of data

The REST API offers also a long list of other endpoints that could be of use at some point, depending on your research interests. Here I'm showing you another two that could be useful, but you can read the documentation of the package for more examples

1) If you know the ID of the tweets, you can download it directly from the API. This is useful because tweets cannot be redistributed as part of the replication materials of a published paper, but the list of tweet IDs can be shared:

```{r}
# Downloading tweets when you know the ID
tw <- lookup_tweets(1196148537525977088)
tw$text
```

2) Lists of Twitter users, compiled by other users, are also accessible through the API.

```{r}
# download user information from a list
new_congress_members <- lists_members(slug = "new-members-of-congress", owner_user = "cspan")
head(new_congress_members)
```

This is also useful if e.g. you're interested in compiling lists of journalists, because media outlets offer these lists in their profiles.
